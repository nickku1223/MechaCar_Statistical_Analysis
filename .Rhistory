plt + geom_boxplot() + facet_wrap(vars(MPG_Type)) + #create multiple boxplots, one for each MPG type
theme(axis.text.x=element_text(angle=45, hjust=1), legend.position = "none") + xlab
plt <- ggplot(mpg_long, aes(x=manufacturer, y=Rating, color=MPG_Type)) #import dataset into ggplot2
plt + geom_boxplot() + facet_wrap(vars(MPG_Type)) + #create multiple boxplots, one for each MPG type
theme(axis.text.x=element_text(angle=45, hjust=1), legend.position = "none") + xlab("Manufacturer")
ggplot(mtcars, aes(x=wt)) + geom_density()
?shapiro.test
shapiro.test(mtcars$wt)
setwd("~/Desktop/UCF-VIRT-DATA-PT-06-2022-U-B-1/15-R/Day_01")
# Character
c <- "This is a string"
# Numeric
a <- 3
b <- 3.1415
d <- "Yet another string"
# Boolean
e <- TRUE
f <- FALSE
g <- T
h <- F
# A vector is a basic unit of data structure in R
# All elements in a vector must be of the same type
disney_characters <- c("mickey", "minnie", "donald", "goofy")
presidents <- c("washington", "adams", "jefferson")
numbers_vector <- c(1, 3, 5, 7, 9, 11)
print(disney_characters)
print(presidents)
print(numbers_vector)
# R is a one-index language!
presidents[1]
### Combine vectors into a single vector
combined_vector <- c(disney_characters, presidents)
combined_vector
### A for-loop
for (x in combined_vector) {
print(x)
}
# Operate over an entire vector en masse
numeric_vector <- 1:length(combined_vector)
squared_vector <- numeric_vector**2
print(combined_vector)
print(numeric_vector)
print(squared_vector)
# An if/else statement
# nchar() returns the number of characters
for (prez in presidents) {
if (nchar(prez) > 5) {
next
}
else {
print(prez)
}
}
# A list, unlike a vector, can contain various data types
random_list <- list("movies"=c("Star Wars", "Titanic", "Avatar"),
"states"=c("California", "Oklahoma", "Texas", "Virginia"),
"coins"=c("penny", "dime", "nickel", "quarter"),
"first_presidents"=presidents,
"nums"=c(1,2,3,4,5),
"bools"=c(T,F,T,T,T,F)
)
# We can use the bracket notation to access an item in a list:
random_list["states"]
# Or use the $ sign
random_list$coins
View(random_list)
# Verify type
typeof(random_list)
roll_call <- function(class){
print(Sys.Date())
# Create a for loop
for (name in students) {
print(name)
}
}
View(roll_call)
roll_call(students)
roll_call <- function(class){
print(Sys.Date())
# Create a for loop
for (name in class) {
print(name)
}
}
# Call the function with the student vector as an argument.
roll_call(students)
roll_call <- function(class){
print(Sys.Date())
# Create a for loop
for (name in class) {
print(name)
}
}
View(roll_call)
# Call the function with the student vector as an argument.
roll_call(students)
# Part I
students <- c(Abraham, Beatrice, Cory, Dinah, Eric, Felicia)
# Call the function with the student vector as an argument.
roll_call(students)
# Part I
students <- c(Abraham, Beatrice, Cory, Dinah, Eric, Felicia)
# Part I
students <- c("Abraham", "Beatrice", "Cory", "Dinah", "Eric", "Felicia")
roll_call <- function(class){
print(Sys.Date())
# Create a for loop
for (name in class) {
print(name)
}
}
# Call the function with the student vector as an argument.
roll_call(students)
locker_combinations <- function(class){
# Create the for loop and print the student name and locker combination.
for (name in class){
print(name, sample(33, 3))
}
}
locker_combinations(students)
locker_combinations <- function(class){
# Create the for loop and print the student name and locker combination.
for (name in class){
print(name + sample(33, 3))
}
}
locker_combinations(students)
locker_combinations <- function(class){
# Create the for loop and print the student name and locker combination.
for (name in class){
combination <- sample(33,3)
print(name, combination)
}
}
locker_combinations(students)
locker_combinations <- function(class){
# Create the for loop and print the student name and locker combination.
for (name in class){
combination <- sample(33,3)
print(name)
print(combination)
}
}
# Call the function with the student vector as an argument.
locker_combinations(students)
for (student in students){
# Create a variable (substring)  that holds the second letter for each student.
second_letter <- substr(student, 2, 2)
# Create an if statement to find the names of students where the
# second letter that is an "e".
if (second_letter == "e"){
new_combinations <- sample(33:66, 3)
print(student)
print(new_combinations)
}
}
library(dplyr)
library(dplyr)
# Simple vectors
# Months of the year
months <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
# Average rainfall/precipitation in NYC during each month
precipitation <- c(3.9, 2.9, 4.1, 3.9, 4.5, 3.5, 4.5, 4.1, 4.0, 3.4, 3.8, 3.6)
length(precipitation)
# Assign names to a vector
# Assign months to precipitation as names
names(precipitation) <- months
# Assign names to a vector
# Assign months to precipitation as names
names(precipitation) <- months
# Display precipitation
print(precipitation)
# Display names of precipitation
print(names(precipitation))
# Access a single member of precipitation by its name
mar_prec <- precipitation$Mar
# Access a single member of precipitation by its name
mar_prec <- precipitation$"Mar"
# Access a single member of precipitation by its name
mar_prec <- precipitation["Mar"]
print(mar_prec)
# Summary of data
# Display summary data of precipitation
summary(precipitation)
# Store the results in a vector.
precipitation_summary <- summary(precipitation)
# Access features of a summary
precipitation_summary["Mean"]
# Use double brackets to access only the value
precipitation_summary[["Mean"]]
# Standard deviation
# Display the standard deviation
sd(precipitation)
# Round SD to two digits
sd(precipitation) %>% round(2)
# A few more methods
# Determine the length of a vector
length(precipitation)
print(yearly_prec)
# Display the sum of a vector
yearly_prec <- sum(precipitation)
print(yearly_prec)
# The same operations, this time using pipes
yearly_prec <- precipitation %>% sum()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
data(diamonds, package='ggplot2')
force(diamonds)
nrow(diamonds)
head(diamonds, 10)
tail(diamonds, 10)
slice(diamonds, 1:7)
slice(diamonds, 3)
slice(diamonds, c(1,7))
select(diamonds, carat, price)
filter(diamonds, cut=='Ideal')
filter(diamonds, (cut=='Ideal' & price > 500))
total_volume <- mutate(diamonds, x * y * z)
total_volume
# In R, variables can contain periods
total.volume2 <- mutate(diamonds, total.volume=(x*y*z))
total.volume2
summarize(diamonds, mean(price))
cut <- group_by(diamonds, cut)
summarize(cut, mean(price), sum(price))
?sample_n()
setwd("~/Desktop/UCF_Bootcamp/Module_15/R_analysis/Demo")
# Read the used_car_data.csv into R
population_table <- read_csv("used_car_data.csv", check.names = F, stringsAsFactors = F)
# Read the used_car_data.csv into R
population_table <- read_csv("used_car_data.csv", check.names=F, stringsAsFactors=F)
# Read the used_car_data.csv into R
population_table <- read.csv('used_car_data.csv',check.names = F,stringsAsFactors = F)
plt <- ggplot(population_table, aes(x=log10(Miles_Driven))) #import the dataset to ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table, aes=(x=log10(Miles_Driven))) #import the dataset to gglplot2
plt + geom_density() #visualize distribution using density plot
plt <- ggplot(sample_table, aes=(x=log10(Miles_Driven))) #import the dataset to gglplot2
plt + geom_density() #visualize distribution using density plot
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density()
?t.test()
t.test(log10(sample_table$Miles_Driven), mu=mean(log10(population_table$Miles_Driven))) #compare sample versus population means
sample_table <- population_table %>% sample_n(50) #generate 50 randomly sampled data points
sample_table2 <- population_table %>% sample_n(50)
t.test(log1-(sample_table$Miles_Driven), log10(sample_table2$Miles_Driven)) #compare means of two samples
t.test(log10(sample_table$Miles_Driven), log10(sample_table2$Miles_Driven)) #compare means of two samples
?t.test()
mpg_data <- read_csv("mpg_modified.csv") #import dataset
View(mpg_data)
mpg_1999 <- mpg_data %>% filter(year==1999) #select only data points where the year is 1999
mpg_2008 <- mpg_data %>% filter(year==2008) #select only data points where the year is 2008
t.text(mpg_1999$hwy, mpg_2008$hwy, paired=T) #compare the mean difference between two samples
t.test(mpg_1999$hwy, mpg_2008$hwy, paired=T) #compare the mean difference between two samples
?nov()
?aov()
mtcars_filt <- mtcars[,c("hp","cyl")] #filter columns from mtcars dataset
mtcars_filt$cyl <- factor(mtcars_filt$cyl) #convert numeric column to factor
aov(hp ~ cyl, data=mtcars_filt) #compare means across multiple levels
summary(aov(hp ~ cyl, data=mtcars_filt))
?cor()
head(mtcars)
plt <- ggplot(mtcars, aes(x=hp, y=qsec)) #import the dataset into ggplot2
plt + geom_point()
cor(mtcars$hp, mtcars$qsec) #calculate correlation coefficient
used_cars <- read.csv("used_car_data.csv", stringsAsFactors = F) #read in the dataset
head(used_cars)
View(used_cars)
# To test whether or not vehicle miles driven and selling price are correlated
plt <- ggplot(used_cars, aes(x=used_cars$Miles_Driven, y=used_cars$Selling_Price)) #import dataset into ggplot2
plt + geom_point() #create a scatter plot
# Use cor() to calculate the Pearson correlation coefficient
cor(used_cars$Miles_Driven, used_cars$Selling_Price) #calculate correlation coefficient
# To produce a correlation matrix for the used_cars dataset
used_matrix <- as.matrix(used_cars[,c("Selling_Price", "Present_Price", "Miles_Driven")]) #convert data frame into numeric matrix
cor(used_matrix)
?lm()
# To create a linear regression model for quarter-mile race time(qsec) and horsepower(hp)
lm(qesc ~ hp, mtcars) #create linear model
# To create a linear regression model for quarter-mile race time(qsec) and horsepower(hp)
lm(qsec ~ hp, mtcars) #create linear model
summary(lm(qsec ~ hp, mtcars)) #summarize linear model
model <- lm(qsec ~ hp, mtcar) #create linear model
model <- lm(qsec ~ hp, mtcars) #create linear model
yvals <- model$coefficients['hp']*mtcar$hp +
model$coefficients['(Intercept)'] #determine y-axis values from linear model
yvals <- model$coefficients['hp']*mtcars$hp +
model$coefficients['(Intercept)'] #determine y-axis values from linear model
plt <- ggplot(mtcars, aes(x=hp, y=qsec)) #import dataset into ggplot2
plt + geom_point() + geom_line(aes(y=yvals), color='red') #plot scatter and linear model
# Multiple linear regression
lm(qsec ~ mpg + disp + drat + wt + hp, data=mtcars) #generate multiple linear regression model
summary(lm(qsec ~ mpg + disp + drat + wt + hp, data=mtcars)) #generate summary statistics
?chisq.test()
table(mpg$class, mpg$year) #generate contingency table
tbl <- table(mpg$class, mpg$year) #generate contingency table
chisq.test(tbl) #compare categorical distritutions
setwd("~/Desktop/UCF_Bootcamp/Module_15/R_analysis/Demo")
setwd("~/Desktop/UCF_Bootcamp/Module_15/MechaCar_Statistical_Analysis")
library(dplyr)
?read_csv
?read.csv
mecha_car <- read.csv("../Data/MechaCar_mpg.csv", check.names = F, stringsAsFactors = F)
mecha_car <- read.csv("./Data/MechaCar_mpg.csv", check.names = F, stringsAsFactors = F)
View(mecha_car)
head(mecha_car)
lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD, mecha_car)
summary(lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD, mecha_car))
# Deliverable 2
suspension_coil <- read.csv("./Suspension_Coil.csv", check.names = F, stringsAsFactors = F)
# Deliverable 2
suspension_coil <- read.csv("./Data/Suspension_Coil.csv", check.names = F, stringsAsFactors = F)
View(suspension_coil)
total_summary <- summarize(suspension_coil$PSI)
total_summary <- summarize(suspension_coil["PSI,
"])
total_summary <- summarize(suspension_coil["PSI"])
View(total_summary)
View(suspension_coil)
View(total_summary)
View(total_summary)
?summarize()
?median()
total_summary <- suspension_coil %>% summarize(Mean=mean(PSI), Median=median(PSI))
View(total_summary)
View(total_summary)
View(total_summary)
?variance()
total_summary <- suspension_coil %>% summarize(Mean=mean(PSI), Median=median(PSI), Variance=var(PSI), SD=sd(PSI))
View(total_summary)
lot_summary <- suspension_coil %>%
group_buy(Manufacturing_Lot) %>%
summarize(Mean=mean(PSI), Median=median(PSI), Variance=var(PSI), SD=sd(PSI))
lot_summary <- suspension_coil %>%
group_by(Manufacturing_Lot) %>%
summarize(Mean=mean(PSI), Median=median(PSI), Variance=var(PSI), SD=sd(PSI))
View(lot_summary)
total_summary <- suspension_coil %>% summarize(Mean=mean(PSI), Median=median(PSI), Variance=var(PSI), SD=sd(PSI))
View(lot_summary)
View(total_summary)
View(suspension_coil)
View(total_summary)
View(lot_summary)
mecha_car_lm <- lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD, mecha_car)
View(mecha_car_lm)
summary <- summary(mecha_car_lm)
View(summary)
summary
setwd("~/Desktop/UCF-VIRT-DATA-PT-06-2022-U-B-1/15-R/Day_02")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
students <-read_csv("students.csv")
head(students)
# unique(dataset, variable) displays unique elements from that column
unique(students$school_name)
school_count <- unique(students$school_name)
# Use length() to identify the number of schools
length(school_count)
paste("There are", length(school_count), "schools")
# nrow() returns the number of rows
student_count <-  nrow(students)
paste("There are a total of", student_count, "students.")
mean_reading_score <- summarize(students, mean(reading_score))
paste("The average reading score is", mean_reading_score)
mean_math_score <- summarize(students, mean(math_score))
paste("The average math score is", mean_math_score)
passing_reading <- filter(students, reading_score >= 70)
passing_reading_count <- nrow(passing_reading)
percentage_passing_reading <- passing_reading_count*100 / student_count
percentage_passing_reading <- round(percentage_passing_reading,2)
paste(percentage_passing_reading, "% of the students have passing reading scores.")
passing_math <- filter(students, math_score >= 70)
passing_math_count <- nrow(passing_math)
percentage_passing_math <- passing_math_count*100 / student_count
percentage_passing_math <- round(percentage_passing_math, 2)
paste(percentage_passing_math, "% of the students have passing math scores.")
overall_passing <- filter(students, math_score >= 70 & reading_score >= 70)
overall_passing_count <- nrow(overall_passing)
percentage_passing_overall <- overall_passing_count *100 / student_count
percentage_passing_overall <- round(percentage_passing_overall , 2)
paste(percentage_passing_overall, "% of the students have passing math and reading scores.")
school_grouping <- group_by(students, school_name)
summarize(school_grouping, avg.reading=mean(reading_score), avg.math = mean(math_score))
grade_grouping <- group_by(students, school_name, grade)
summarize(grade_grouping, avg.reading=mean(reading_score), avg.math=mean(math_score))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
data(diamonds, package='ggplot2')
nrow(diamonds)
head(diamonds, 10)
tail(diamonds, 10)
slice(diamonds, 1:7)
slice(diamonds, 3)
slice(diamonds, c(1,7))
select(diamonds, carat, price)
filter(diamonds, cut=='Ideal')
filter(diamonds, (cut=='Ideal' & price > 500))
total_volume <- mutate(diamonds, x * y * z)
total_volume
# In R, variables can contain periods
total.volume2 <- mutate(diamonds, total.volume=(x*y*z))
total.volume2
summarize(diamonds, mean(price))
cut <- group_by(diamonds, cut)
summarize(cut, mean(price), sum(price))
summarize(cut, avg=mean(price),number=n())
cut2 <- group_by(diamonds, cut, color)
cut2_summary <- summarize(cut2, mean(price))
cut2_summary
count(diamonds, cut)
set.seed(42)
population1 = rnorm(1000)
population2 = sample(population1, 200)
?set.seed()
t.test(population2, mu=mean(population1))
# Generate data with a bigger difference in means
population3 = rnorm(1000, -2)
t.test(population2, mu=mean(population3))
set.seed(42)
population1 = rnorm(1000)
population2 = rnorm(1000)
t.test(population1, population2)
population1 = rnorm(1000)
population2 = rnorm(1000, -2)
t.test(population1, population2)
sardines <- read.csv(file="03-Stu_Sardines/Resources/sardines.csv")
# Calculate the population mean for Sardine Vertebrae in Alaska.
# Hint: use the subset() function to get only the data for Alaska.
population1 = subset(sardines, location == 1)
sardines <- read.csv(file="03-Stu_Sardines/Resources/sardines.csv")
View(sardines)
sardines <- read.csv(file="../Resources/sardines.csv")
setwd("~/Desktop/UCF-VIRT-DATA-PT-06-2022-U-B-1/15-R/Day_02/03-Stu_Sardines/Solved")
sardines <- read.csv(file="../Resources/sardines.csv")
View(sardines)
?subset()
# Calculate the population mean for Sardine Vertebrae in Alaska (1).
# Hint: use the subset() function to get only the data for Alaska.
alaska <- subset(sardines, location == 1)
mean(alaska[["vertebrae"]])
# Calculate the population mean for Sardine Vertebrae in San Diego.
# Hint: use the subset() function to get only the data for San Diego.
san_diego <- subset(sardines, location == 6)
mean(san_diego[["vertebrae"]])
# Calculate Independent (Two Sample) T-Test
t.test(alaska[["vertebrae"]], san_diego[["vertebrae"]])
setwd("~/Desktop/UCF-VIRT-DATA-PT-06-2022-U-B-1/15-R/Day_02/04-Ins_ANOVA/Solved")
library(tidyverse)
mosquito <- read.csv(file="04-Ins_ANOVA/Resources/mosquito.csv")
mosquito <- read.csv(file="../Resources/mosquito.csv")
View(mosquito)
ggplot(mosquito,aes(x=factor(treatment),y=mosq)) + geom_boxplot()
# aov performs the analysis of variance, but does not provide a p-value
aov(mosq ~ factor(treatment), data=mosquito)
# to obtain a p-value, wrap aov() with a summary() function
summary(aov(mosq ~ factor(treatment), data=mosquito))
setwd("~/Desktop/UCF-VIRT-DATA-PT-06-2022-U-B-1/15-R/Day_02/05-Stu_ANOVA/Solved")
# Read in the CSV file.
hair <- read.csv(file="../Resources/hair.csv")
# Read in the CSV file.
hair <- read.csv(file="../Resources/hair.csv")
View(hair)
# Plot the data using ggplot
ggplot(hair,aes(x=HairColour,y=Pain)) + geom_boxplot()
# Determine the p-value using ANOVA
summary(aov(Pain ~ HairColour, data=hair))
setwd("~/Desktop/UCF_Bootcamp/Module_15/MechaCar_Statistical_Analysis")
# read in the csv file
mecha_car <- read.csv("./Data/MechaCar_mpg.csv", check.names = F, stringsAsFactors = F)
# perform linear regession using the lm() function,  and pass all six variables (columns)
mecha_car_lm <- lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD, mecha_car)
mecha_car_lm
summary <- summary(mecha_car_lm)
summary
# Deliverable 3
#using the t.test() function to determine if the PSI across all manufacturing lots is statistically different from the population mean of 1,500 pounds per square inch.
t.test(suspension_coil$PSI, mu=1500)
# Deliverable 3
#using the t.test() function to determine if the PSI across all manufacturing lots is statistically different from the population mean of 1,500 pounds per square inch.
t.test(suspension_coil$PSI, mu=1500)
library(dplyr)
# Deliverable 1
# read in the csv file
mecha_car <- read.csv("./Data/MechaCar_mpg.csv", check.names = F, stringsAsFactors = F)
# perform linear regession using the lm() function,  and pass all six variables (columns)
mecha_car_lm <- lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD, mecha_car)
mecha_car_lm
# get summary statistic
summary <- summary(mecha_car_lm)
summary
# Deliverable 2
# read in the csv file
suspension_coil <- read.csv("./Data/Suspension_Coil.csv", check.names = F, stringsAsFactors = F)
# create a total_summary data frame using summarize() function to get the mean, median, variance, and standard deviation of the suspension coil's PSI column.
total_summary <- suspension_coil %>% summarize(Mean=mean(PSI), Median=median(PSI), Variance=var(PSI), SD=sd(PSI))
# creates a lot_summary dataframe using the group_by() and the summarize() functions to group each manufacturing lot by the mean, median, variance, and standard deviation of the suspension coilâ€™s PSI column.
lot_summary <- suspension_coil %>%
group_by(Manufacturing_Lot) %>%
summarize(Mean=mean(PSI), Median=median(PSI), Variance=var(PSI), SD=sd(PSI))
# Deliverable 3
#using the t.test() function to determine if the PSI across all manufacturing lots is statistically different from the population mean of 1,500 pounds per square inch.
t.test(suspension_coil$PSI, mu=1500)
#using the t.test() function and its subset() argument to determine if the PSI for each manufacturing lot is statistically different from the population mean of 1,500 pounds per square inch.
# Lot 1
t.test(subset(suspension_coil, Manufacturing_Lot=="Lot1")$PSI, mu=1500)
# Lot 2
t.test(subset(suspension_coil, Manufacturing_Lot=="Lot2")$PSI, mu=1500)
# Lot 3
t.test(subset(suspension_coil, Manufacturing_Lot=="Lot3")$PSI, mu=1500)
